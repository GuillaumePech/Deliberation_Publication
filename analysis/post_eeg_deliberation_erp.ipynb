{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_trials(epochs, chs=[0], do_peak=0, do_mean=0, do_slope=0, T1=0, T2=0, iter_inf=False):\n",
    "    # Create a copy of epochs\n",
    "    \n",
    "    from scipy.stats import iqr\n",
    "    from scipy.stats import median_abs_deviation as mad\n",
    "\n",
    "    new_epochs = epochs.copy()\n",
    "    # Create a list to keep track of trial status (1 for good trials, 0 for rejected trials)\n",
    "    list_trials = np.ones(len(new_epochs))\n",
    "\n",
    "    for j in chs:\n",
    "        # Initialize variables for peak rejection\n",
    "        peak_rejection = 0\n",
    "        mean_rejection = 0\n",
    "        slope_rejection = 0\n",
    "        ite_peak = 0\n",
    "        ite_mean = 0\n",
    "        ite_slope = 0\n",
    "        stop_peak = 0\n",
    "        stop_mean = 0\n",
    "        stop_slope = 0\n",
    "        ite_loop = 0\n",
    "\n",
    "        # Main loop for outlier detection and rejection\n",
    "        while ite_mean > -1:\n",
    "            ite_loop += 1\n",
    "\n",
    "            if do_peak == 1:\n",
    "                if ite_peak == 0:\n",
    "                    # Calculate time indices based on T1 and T2 values\n",
    "                    time1 = np.where(new_epochs.times < T1)[0][-1]\n",
    "                    time2 = np.where(new_epochs.times < T2)[0][-1]\n",
    "\n",
    "                    # Calculate peak-to-peak values for each trial and channel\n",
    "                    peak_to_peak = np.array([max(new_epochs._data[i][j][time1:time2]) - min(new_epochs._data[i][j][time1:time2]) for i in range(len(new_epochs._data))], dtype=np.dtype(float))\n",
    "\n",
    "                idx = []\n",
    "                for i in range(len(new_epochs._data)):\n",
    "                    value_prtp = peak_to_peak[i]\n",
    "\n",
    "                    # Check if the value exceeds the upper threshold for peak rejection\n",
    "                    outlier_up_peak = np.nanmedian(peak_to_peak) + (3 * mad(peak_to_peak, scale='normal', nan_policy='omit'))\n",
    "                    if value_prtp > outlier_up_peak:\n",
    "                        idx.append(i)\n",
    "\n",
    "                if len(idx) == 0:\n",
    "                    # No more outliers found, stop peak outlier detection\n",
    "                    stop_peak = 1\n",
    "                else:\n",
    "                    ite_peak += 1\n",
    "                    peak_to_peak[idx] = None\n",
    "                    list_trials[idx] = 0\n",
    "                    peak_rejection += len(idx)\n",
    "\n",
    "            if do_slope == 1:\n",
    "                if ite_slope == 0:\n",
    "                    # Calculate time indices based on T1 and T2 values\n",
    "                    time1 = np.where(new_epochs.times < T1)[0][-1]\n",
    "                    time2 = np.where(new_epochs.times < T2)[0][-1]\n",
    "\n",
    "                    x = new_epochs.times[time1:time2]\n",
    "                    # Calculate slopes for each trial and channel\n",
    "                    slopes_trials = np.array([np.polyfit(x, new_epochs._data[i, j, time1:time2], 1)[0] for i in range(len(new_epochs._data))], dtype=np.dtype(float))\n",
    "\n",
    "                idx = []\n",
    "                for i in range(len(new_epochs._data)):\n",
    "                    value_prtp = slopes_trials[i]\n",
    "\n",
    "                    # Check if the value exceeds the upper and lower thresholds for slope rejection\n",
    "                    outlier_up_mean = np.nanmedian(slopes_trials) + (3 * mad(slopes_trials, scale='normal', nan_policy='omit'))\n",
    "                    outlier_down_mean = np.nanmedian(slopes_trials) - (3 * mad(slopes_trials, scale='normal', nan_policy='omit'))\n",
    "                    if value_prtp > outlier_up_mean:\n",
    "                        idx.append(i)\n",
    "                    elif value_prtp < outlier_down_mean:\n",
    "                        idx.append(i)\n",
    "\n",
    "                if len(idx) == 0:\n",
    "                    # No more outliers found, stop slope outlier detection\n",
    "                    stop_slope = 1\n",
    "                else:\n",
    "                    ite_slope += 1\n",
    "                    slopes_trials[idx] = None\n",
    "                    list_trials[idx] = 0\n",
    "                    slope_rejection += len(idx)\n",
    "\n",
    "            if do_mean == 1:\n",
    "                if ite_mean == 0:\n",
    "                    # Calculate time indices based on T1 and T2 values\n",
    "                    time1 = np.where(new_epochs.times < T1)[0][-1]\n",
    "                    time2 = np.where(new_epochs.times < T2)[0][-1]\n",
    "                    # Calculate mean values for each trial and channel\n",
    "                    mean_trials = np.array([np.mean(new_epochs._data[i][j][time1:time2]) for i in range(len(new_epochs._data))], dtype=np.dtype(float))\n",
    "\n",
    "                idx = []\n",
    "                for i in range(len(new_epochs._data)):\n",
    "                    value_prtp = mean_trials[i]\n",
    "\n",
    "                    # Check if the value exceeds the upper and lower thresholds for mean rejection\n",
    "                    outlier_up_mean = np.nanmedian(mean_trials) + (3 * mad(mean_trials, scale='normal', nan_policy='omit'))\n",
    "                    outlier_down_mean = np.nanmedian(mean_trials) - (3 * mad(mean_trials, scale='normal', nan_policy='omit'))\n",
    "                    if value_prtp > outlier_up_mean:\n",
    "                        idx.append(i)\n",
    "                    elif value_prtp < outlier_down_mean:\n",
    "                        idx.append(i)\n",
    "\n",
    "\n",
    "                if len(idx) == 0:\n",
    "                    # No more outliers found, stop mean outlier detection\n",
    "                    stop_mean = 1\n",
    "                else:\n",
    "                    ite_mean += 1\n",
    "                    mean_trials[idx] = None\n",
    "                    list_trials[idx] = 0\n",
    "                    mean_rejection += len(idx)\n",
    "\n",
    "            # Check if any outlier detection is disabled\n",
    "            if do_peak == 0 | iter_inf == False :\n",
    "                stop_peak = 1\n",
    "            if do_mean == 0 | iter_inf == False:\n",
    "                stop_mean = 1\n",
    "            if do_slope == 0 | iter_inf == False:\n",
    "                stop_slope = 1\n",
    "\n",
    "            # Check if all outlier detection has stopped\n",
    "            if stop_mean == 1 and stop_peak == 1 and stop_slope == 1:\n",
    "                # No more outlier detection, stop the loop\n",
    "                break\n",
    "\n",
    "    # Drop the trials marked for removal and return the modified epochs object\n",
    "    new_epochs.drop(np.where(list_trials == 0)[0])\n",
    "    return new_epochs, peak_rejection, mean_rejection, slope_rejection, list_trials, ite_loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, mne, csv, re\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from mne.epochs import equalize_epoch_counts\n",
    "\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#set directory pathway\n",
    "os.chdir('C:/Users/mfbpe/Desktop/DATA/2022_deliberation/derivatives/')\n",
    "data_files = glob('*ica_raw.fif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "all=[]\n",
    "participant = []\n",
    "good_participant = []\n",
    "drop_stats=[]\n",
    "RT_part=[]\n",
    "list_bad=[]\n",
    "nb_delete={}\n",
    "conditions = ['Arbi','Edeli','Hdeli']\n",
    "# data_files_epochs = glob('*ica_hand_epo.fif')\n",
    "\n",
    "datafile=open(\"data_RP.csv\",\"w\", newline=\"\")\n",
    "writer=csv.writer(datafile, delimiter=\";\")\n",
    "writer.writerow([\"Participant\", \"conditions\",\"Trial_RP\",\"outlier_RP\",\"RT_RP\", 'mean_RP_early','slope_RP_early', 'mean_RP_late','slope_RP_late', 'mean_RP','slope_RP'])\n",
    "\n",
    "for part in range(len(data_files)):\n",
    "    raw = mne.io.read_raw_fif(data_files[part],preload=True)\n",
    "    n_part = int(re.split( \"sub-|_2023\",data_files[part])[1])\n",
    "    \n",
    "    if part == 0 :\n",
    "        sphere = mne.make_sphere_model('auto', 'auto', raw.info)\n",
    "        src = mne.setup_volume_source_space(sphere=sphere)\n",
    "        forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)\n",
    "    raw.set_eeg_reference('REST', forward=forward)\n",
    "\n",
    "    events = mne.find_events(raw, shortest_event=1)\n",
    "    ite_delete=0\n",
    "    \n",
    "    while events[0,2] not in [10,20,30] :\n",
    "        events = np.delete(events,0,0)\n",
    "        ite_delete+=1\n",
    "    nb_delete[n_part]=ite_delete\n",
    "    if part == 48:\n",
    "        events[34,2]=20\n",
    "    events = mne.merge_events(events, [13,14,15], 13)  # Beep Arbi\n",
    "    events = mne.merge_events(events, [23,24,25], 23)  # Beep Edeli\n",
    "    events = mne.merge_events(events, [33,34,35], 33)  # Beep Hdeli\n",
    "    \n",
    "    events = mne.merge_events(events, [11,12], 11)  # Hand Arbi\n",
    "    events = mne.merge_events(events, [21,22], 21)  # Hand Edeli\n",
    "    events = mne.merge_events(events, [31,32], 31)  # Hand Hdeli\n",
    "                \n",
    "                \n",
    "    event_dict = {'Vis/Arbi':10,'Vis/Edeli':20,'Vis/Hdeli':30}\n",
    "\n",
    "    # # try :\n",
    "    vis= mne.Epochs(raw, events,baseline =None,event_id=event_dict,\n",
    "            tmin=-1.1, tmax=0,preload=True, detrend=None, on_missing='ignore', picks='Cz')\n",
    "     \n",
    "    vis_events= mne.Epochs(raw, events,baseline =None,event_id=event_dict,\n",
    "            tmin=-.1, tmax=0,preload=True, detrend=None, on_missing='ignore', picks='Cz') \n",
    "\n",
    "    event_dict = {'Hand/Arbi':11,'Hand/Edeli':21,'Hand/Hdeli':31}\n",
    "\n",
    "    epochs= mne.Epochs(raw, events,baseline =None,event_id=event_dict,\n",
    "            tmin=-3, tmax=1,preload=True, detrend=None, on_missing='ignore', picks='Cz') \n",
    "\n",
    "    hand = epochs['Hand']\n",
    "\n",
    "    data = [round((hand.events[x,0]-vis_events.events[x,0])/512,2) for x in range(len(vis_events.events))]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    hand.shift_time(.1)\n",
    "    hand.apply_baseline((-.05,.05))\n",
    "    _,_,_,_,list_ti,_ = drop_trials(hand, do_mean=1, do_peak=1, do_slope=1, T1=-1,T2=0, chs=np.arange(len(epochs.ch_names)))\n",
    "    drop_stats.append(sum(list_ti==0)/len(list_ti))\n",
    "\n",
    "    time1_RP_early = np.where(hand.times<-1)[0][-1]\n",
    "    time2_RP_early = np.where(hand.times<-.5)[0][-1]\n",
    "    x_early = epochs.times[time1_RP_early:time2_RP_early]\n",
    "    time1_RP_late = np.where(hand.times<-.5)[0][-1]\n",
    "    time2_RP_late = np.where(hand.times<-0)[0][-1]\n",
    "    x_late = epochs.times[time1_RP_late:time2_RP_late]\n",
    "    x = epochs.times[time1_RP_early:time2_RP_late]\n",
    "    hand._data *=1e6\n",
    "\n",
    "    for ite_trial in range(len(hand)):\n",
    "        RP_mean_early = np.mean(hand._data[ite_trial,0,time1_RP_early:time2_RP_early])\n",
    "        RP_slope_early = np.polyfit(x_early,hand._data[ite_trial,0, time1_RP_early:time2_RP_early],1)[0]\n",
    "        RP_mean_late = np.mean(hand._data[ite_trial,0,time1_RP_late:time2_RP_late])\n",
    "        RP_slope_late = np.polyfit(x_late,hand._data[ite_trial,0, time1_RP_late:time2_RP_late],1)[0]\n",
    "        RP_mean = np.mean(hand._data[ite_trial,0,time1_RP_early:time2_RP_late])\n",
    "        RP_slope = np.polyfit(x,hand._data[ite_trial,0, time1_RP_early:time2_RP_late],1)[0]\n",
    "        writer.writerow([n_part,  hand.events[ite_trial,2],ite_trial, list_ti[ite_trial],data[ite_trial],round(RP_mean_early,3), round(RP_slope_early,3),round(RP_mean_late,3), round(RP_slope_late,3),round(RP_mean,3), round(RP_slope,3)])\n",
    "\n",
    "    hand.drop(np.where(list_ti==0)[0])\n",
    "    hand.save(data_files[part].split('raw')[0]+'clean_rest_baseline005_02_03_2024_V2_epo.fif', overwrite=True)\n",
    "\n",
    "    \n",
    "datafile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, mne, csv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('C:/Users/mfbpe/Desktop/DATA/2022_deliberation/derivatives/')\n",
    "data_files = glob('*clean_rest_baseline005_02_03_2024_epo.fif')\n",
    "data_files=np.delete(data_files,[10,23,25])\n",
    "hand_all = [mne.read_epochs(x)  for x in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "gr = [x.apply_baseline((-.05,.05)).average() for x in hand_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "for  cond in ['Arbi','Edeli','Hdeli']:\n",
    "    gr_all[cond] = [x[cond].apply_baseline((-0.05, 0.05)).crop(-1,.1).average(method=\"mean\") for c,x in enumerate(hand_all) if c not in [30,31]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Figure size 1400x1050 with 2 Axes>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "mne.viz.plot_compare_evokeds(gr_all, ylim=dict(eeg=[-1.5e6, 3e6]),\n",
    "                            linestyles=['solid', 'solid', 'solid'],  # Line styles for each grand average\n",
    "                             styles={'Arbi': {\"linewidth\": 4},  # Style settings for the first grand average\n",
    "                                     'Edeli': {\"linewidth\": 4},  # Style settings for the second grand average\n",
    "                                     'Hdeli': {\"linewidth\": 4},  # Style settings for the third grand average\n",
    "                                     },\n",
    "                             \n",
    "                             colors=[\"#f26d41\",\"#40b2d8\", \"#ac4bd8\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
